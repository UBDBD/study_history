{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22159e11-654b-4ee5-85bc-a36b0a769c2d",
   "metadata": {},
   "source": [
    "# Understanding and preprocessing parallel corpus data \n",
    "- Parallel data pairs are not equal in length\n",
    "- ex) '나는 학생이다.'(2) -> 'I am a student.'(4)\n",
    "    - Use padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f091de-f7cf-4a63-b31a-a9bd5bb8d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib3\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dac1d7a-5017-4bca-809e-e17f95a27f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file download to fra-eng.zip\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def download_zip(url, output_path):\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"ZIP file download to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to downlod. HTTP Response Code: {response.status_code}\")\n",
    "\n",
    "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "output_path = \"fra-eng.zip\"\n",
    "download_zip(url, output_path)\n",
    "\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, output_path)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf41edd6-f868-46a5-a518-f68e08c4b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 232736\n"
     ]
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "print(f'Samples: {len(lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7183e996-3f5f-4683-8be0-8ea993a3984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40872</th>\n",
       "      <td>I don't like coffee.</td>\n",
       "      <td>Je n'apprécie pas le café.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31671</th>\n",
       "      <td>You're both wrong.</td>\n",
       "      <td>Vous avez toutes deux tort.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>I love hiking.</td>\n",
       "      <td>J'adore les excursions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32642</th>\n",
       "      <td>Everyone liked you.</td>\n",
       "      <td>Tout le monde vous appréciait.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29958</th>\n",
       "      <td>Tom coughed again.</td>\n",
       "      <td>Tom toussait à nouveau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46830</th>\n",
       "      <td>Be proud of yourself.</td>\n",
       "      <td>Soyez fiers de vous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27345</th>\n",
       "      <td>I ripped my pants.</td>\n",
       "      <td>J'ai déchiré mon pantalon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45090</th>\n",
       "      <td>Was I really boring?</td>\n",
       "      <td>Étais-je vraiment si ennuyeuse ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15735</th>\n",
       "      <td>I need a helmet.</td>\n",
       "      <td>Il me faut un casque.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38607</th>\n",
       "      <td>You have to get up.</td>\n",
       "      <td>Tu dois te lever.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                               tar\n",
       "40872   I don't like coffee.        Je n'apprécie pas le café.\n",
       "31671     You're both wrong.       Vous avez toutes deux tort.\n",
       "7988          I love hiking.           J'adore les excursions.\n",
       "32642    Everyone liked you.    Tout le monde vous appréciait.\n",
       "29958     Tom coughed again.           Tom toussait à nouveau.\n",
       "46830  Be proud of yourself.              Soyez fiers de vous.\n",
       "27345     I ripped my pants.        J'ai déchiré mon pantalon.\n",
       "45090   Was I really boring?  Étais-je vraiment si ennuyeuse ?\n",
       "15735       I need a helmet.             Il me faut un casque.\n",
       "38607    You have to get up.                 Tu dois te lever."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # use 60,000 samples\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2e9e42-aecd-4ba8-af19-5dadb5a1778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57250</th>\n",
       "      <td>I gave Tom a huge hug.</td>\n",
       "      <td>\\t J'ai fait à Tom un gros câlin. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25830</th>\n",
       "      <td>Don't forget that.</td>\n",
       "      <td>\\t N'oublie pas ça. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59046</th>\n",
       "      <td>Isn't that suspicious?</td>\n",
       "      <td>\\t N'est-ce pas suspect ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59056</th>\n",
       "      <td>It didn't hurt at all.</td>\n",
       "      <td>\\t Ça n'a pas fait mal du tout. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49901</th>\n",
       "      <td>I'll apologize later.</td>\n",
       "      <td>\\t Je présenterai plus tard mes excuses. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39619</th>\n",
       "      <td>Do you like bananas?</td>\n",
       "      <td>\\t Aimes-tu les bananes? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39805</th>\n",
       "      <td>Don't obey that man.</td>\n",
       "      <td>\\t N'obéis pas à cet homme. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>Pardon me?</td>\n",
       "      <td>\\t Quoi ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23760</th>\n",
       "      <td>Tom reads slowly.</td>\n",
       "      <td>\\t Tom lit lentement. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23016</th>\n",
       "      <td>The man stood up.</td>\n",
       "      <td>\\t L'homme se leva. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                          tar\n",
       "57250  I gave Tom a huge hug.         \\t J'ai fait à Tom un gros câlin. \\n\n",
       "25830      Don't forget that.                       \\t N'oublie pas ça. \\n\n",
       "59046  Isn't that suspicious?                 \\t N'est-ce pas suspect ? \\n\n",
       "59056  It didn't hurt at all.           \\t Ça n'a pas fait mal du tout. \\n\n",
       "49901   I'll apologize later.  \\t Je présenterai plus tard mes excuses. \\n\n",
       "39619    Do you like bananas?                  \\t Aimes-tu les bananes? \\n\n",
       "39805    Don't obey that man.               \\t N'obéis pas à cet homme. \\n\n",
       "1460               Pardon me?                                 \\t Quoi ? \\n\n",
       "23760       Tom reads slowly.                     \\t Tom lit lentement. \\n\n",
       "23016       The man stood up.                       \\t L'homme se leva. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n') # \\t: <sos>, \\n: <eos>\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8c3e43-6e91-4e3b-b59d-2e6719655cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vocab\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1 line\n",
    "    for char in line: # 1 character\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db26a2d-4052-4728-9b7b-ef556b350a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source vocab size : 80\n",
      "target vocab size : 102\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print('source vocab size :',src_vocab_size)\n",
    "print('target vocab size :',tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e1a630-5ca6-46c8-800d-c8fa8ed0c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c44865-2fec-42c5-880c-8b7a5309b835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, 'ï': 77, '’': 78, '€': 79}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, ',': 10, '-': 11, '.': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '«': 77, '»': 78, 'À': 79, 'Ç': 80, 'É': 81, 'Ê': 82, 'Ô': 83, 'à': 84, 'â': 85, 'ç': 86, 'è': 87, 'é': 88, 'ê': 89, 'ë': 90, 'î': 91, 'ï': 92, 'ô': 93, 'ù': 94, 'û': 95, 'œ': 96, '\\u2009': 97, '‘': 98, '’': 99, '\\u202f': 100, '‽': 101}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93eae58-cf0a-41ee-b498-0e170e2371fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source encoding : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "for line in lines.src:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "print(\"source encoding :\", encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9efb245b-0032-429b-85e5-c03e4f99f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target encoding : [[1, 3, 46, 50, 3, 4, 3, 2], [1, 3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [1, 3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [1, 3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [1, 3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    encoded_line.append(tar_to_index[char])\n",
    "  decoder_input.append(encoded_line)\n",
    "print('target encoding :',decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a55072-9e21-4926-ad2f-0fbc7501f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target label encoding : [[3, 46, 50, 3, 4, 3, 2], [3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "  timestep = 0\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    if timestep > 0:\n",
    "      encoded_line.append(tar_to_index[char])\n",
    "    timestep = timestep + 1\n",
    "  decoder_target.append(encoded_line)\n",
    "print('target label encoding :',decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2767b031-1fb1-4a18-9518-36f8cfa333fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source max length : 22\n",
      "target max length : 76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('source max length :',max_src_len)\n",
    "print('target max length :',max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912b9c7e-e4b2-4e59-81ac-583fa89ee05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746f1eee-edc1-4bc2-b29c-938590444022",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8ae9d-27e8-45dc-b4f8-16966e1aebb0",
   "metadata": {},
   "source": [
    "# Teacher forcing\n",
    "Why we need 'decoder_input'\n",
    "- Previous predicts can be wrong, causing the current predict to be wrong.\n",
    "    - In the training session, Use actual values as input instead of predicted values from a previous time step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226be3df-a678-41e8-b89b-f1756ce93f97",
   "metadata": {},
   "source": [
    "# Seq2Seq train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "854d30ae-a363-4eba-b544-501b1fc8c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38104d60-ab83-446f-a0f5-ccfe7fdf26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "\n",
    "# not use 'encoder_outputs' in this phase\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM have two states: hidden state and cell state\n",
    "encoder_states = [state_h, state_c] # context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b6ac505-230e-4ce4-9188-d3ceb797a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# give hidden stats and cell state to decoder\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7266f30a-19bf-4c27-a042-55afff757d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 109s 144ms/step - loss: 0.7263 - val_loss: 0.6284\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 117s 157ms/step - loss: 0.4429 - val_loss: 0.5079\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 0.3700 - val_loss: 0.4506\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 124s 166ms/step - loss: 0.3286 - val_loss: 0.4152\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 121s 162ms/step - loss: 0.3005 - val_loss: 0.3900\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 0.2800 - val_loss: 0.3716\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 122s 163ms/step - loss: 0.2641 - val_loss: 0.3612\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 122s 163ms/step - loss: 0.2513 - val_loss: 0.3538\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 124s 165ms/step - loss: 0.2406 - val_loss: 0.3448\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 124s 166ms/step - loss: 0.2314 - val_loss: 0.3408\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 124s 166ms/step - loss: 0.2233 - val_loss: 0.3370\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 124s 165ms/step - loss: 0.2160 - val_loss: 0.3364\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 120s 161ms/step - loss: 0.2095 - val_loss: 0.3310\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 120s 161ms/step - loss: 0.2036 - val_loss: 0.3320\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 0.1981 - val_loss: 0.3304\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 123s 164ms/step - loss: 0.1931 - val_loss: 0.3292\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 0.1884 - val_loss: 0.3299\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 120s 160ms/step - loss: 0.1841 - val_loss: 0.3291\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 121s 162ms/step - loss: 0.1799 - val_loss: 0.3305\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 123s 164ms/step - loss: 0.1761 - val_loss: 0.3313\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 0.1724 - val_loss: 0.3323\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 122s 163ms/step - loss: 0.1690 - val_loss: 0.3344\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 125s 167ms/step - loss: 0.1657 - val_loss: 0.3359\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 132s 176ms/step - loss: 0.1626 - val_loss: 0.3371\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 130s 173ms/step - loss: 0.1597 - val_loss: 0.3399\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 130s 173ms/step - loss: 0.1568 - val_loss: 0.3409\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 131s 175ms/step - loss: 0.1541 - val_loss: 0.3445\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 131s 175ms/step - loss: 0.1516 - val_loss: 0.3471\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 129s 172ms/step - loss: 0.1491 - val_loss: 0.3480\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 129s 171ms/step - loss: 0.1467 - val_loss: 0.3509\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 128s 171ms/step - loss: 0.1446 - val_loss: 0.3516\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 125s 167ms/step - loss: 0.1424 - val_loss: 0.3552\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 126s 168ms/step - loss: 0.1402 - val_loss: 0.3569\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 131s 175ms/step - loss: 0.1383 - val_loss: 0.3616\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 131s 175ms/step - loss: 0.1363 - val_loss: 0.3624\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 131s 174ms/step - loss: 0.1345 - val_loss: 0.3653\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 129s 171ms/step - loss: 0.1326 - val_loss: 0.3670\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 129s 171ms/step - loss: 0.1310 - val_loss: 0.3700\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 130s 174ms/step - loss: 0.1293 - val_loss: 0.3746\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 123s 164ms/step - loss: 0.1277 - val_loss: 0.3776\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 123s 164ms/step - loss: 0.1262 - val_loss: 0.3785\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 120s 160ms/step - loss: 0.1246 - val_loss: 0.3827\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 123s 163ms/step - loss: 0.1232 - val_loss: 0.3833\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 120s 160ms/step - loss: 0.1218 - val_loss: 0.3874\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 119s 159ms/step - loss: 0.1205 - val_loss: 0.3888\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 130s 174ms/step - loss: 0.1191 - val_loss: 0.3914\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 125s 166ms/step - loss: 0.1179 - val_loss: 0.3948\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 130s 173ms/step - loss: 0.1167 - val_loss: 0.3958\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 130s 174ms/step - loss: 0.1154 - val_loss: 0.3975\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 128s 170ms/step - loss: 0.1142 - val_loss: 0.4010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1745a5cd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1cac4-1c78-41ad-8e8d-a0b9eff13852",
   "metadata": {},
   "source": [
    "# Seq2Seq translation\n",
    "1. Input sentence enters the encoder to get the hidden state and cell state.\n",
    "2. Send the state and a '\\t' to the decoder.\n",
    "3. Decoder repeats predicting the next character until it sees '\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ec687e-e7c5-4888-8a84-61eaac110781",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "277853c1-ab47-473a-a67a-c8e3387eaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tensor of saving previous time step\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# use 'initial_state' to predict next word\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# keep hidden state and cell state\n",
    "decoder_states =  [state_h, state_c]\n",
    "decoder_outputs =  decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24593a67-fe02-4481-bbb9-0c8b61dbf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2856c6fb-0de1-4a73-a79a-14cfc887b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # get the state of the encoder from the input sequence\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # generate a one-hot vector corresponding to <sos>\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # loop until 'stop_condition = True'\n",
    "    while not stop_condition:\n",
    "        # Use privious stats_values as current states\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # predict result to text\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # append predict characters from current time step in to current predict sentence\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # stop when <eos> is reached or the maximum length is exceeded\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # save current predict result for next step\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # save current states for next states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b643855f-ef24-4bdf-a5d0-d07050cef952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "\n",
      "input sentence: Go.\n",
      "target sentence: Bouge ! \n",
      "result sentence: Courage. \n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "\n",
      "input sentence: Hello!\n",
      "target sentence: Bonjour ! \n",
      "result sentence: Bonjour ! \n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "\n",
      "input sentence: Got it!\n",
      "target sentence: J'ai pigé ! \n",
      "result sentence: Courage ! \n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "\n",
      "input sentence: Go home.\n",
      "target sentence: Rentre à la maison. \n",
      "result sentence: Rentre à la maison. \n",
      "-----------------------------------\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "\n",
      "input sentence: Forget me.\n",
      "target sentence: Oublie-moi. \n",
      "result sentence: Oublie Tom. \n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]: # index of input sentence\n",
    "    input_seq = encoder_input[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print()\n",
    "    print('input sentence:', lines.src[seq_index])\n",
    "    print('target sentence:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) #exclude '\\t', '\\n'\n",
    "    print('result sentence:', decoded_sentence[1:len(decoded_sentence)-1]) # exclude '\\n'\n",
    "    print(35 * \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511b382-5233-4635-9787-fb9f4309a018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
